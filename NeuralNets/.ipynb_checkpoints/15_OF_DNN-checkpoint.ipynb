{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nyuad/anaconda2/envs/Gabor/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== IMPORTING ||| SCRIPT STARTS ||| LOGGING PURPOSE ======\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import double_log\n",
    "def print(*args, **kwargs):\n",
    "    return double_log.print(*args, **kwargs)\n",
    "\n",
    "import keras\n",
    "import pickle\n",
    "import operator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import plot_conf_matrix as pcm\n",
    "from keras import backend as K\n",
    "from keras.datasets import mnist\n",
    "from keras.engine.topology import Layer\n",
    "from keras.models import Sequential, Model\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from keras.layers import Dense, Dropout, Softmax, BatchNormalization, LeakyReLU, ELU, ThresholdedReLU\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "reload(pcm)\n",
    "\n",
    "print(\"===== IMPORTING ||| SCRIPT STARTS ||| LOGGING PURPOSE ======\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data, Splitting, and Correct Fromating\n",
    "As my noisy dataset, I use MNIST but I flipped the labels with 50% probability to something else with a random distribution. As my ground truth, I use the clean MNIST. You can see the noise distribution in the confusion matrix below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "caucasian     5150\n",
       "eastasian     1549\n",
       "southasian     465\n",
       "Name: race, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('../Data/uniform_table.csv')\n",
    "train = train[train['ethnicity'] != 'hispanic']\n",
    "\n",
    "test = pd.read_csv('../Data/feret_table.csv')\n",
    "test = test[test['race'] != \"other\"]\n",
    "test = test[test['race'] != \"african\"]\n",
    "test = test[test['race'] != \"hispanic\"]\n",
    "test['race'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(116009, 128) (116009,) train shape\n",
      "(7164, 128) (7164,) test shape\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 3\n",
    "epochs = 50\n",
    "input_shape = (128,)\n",
    "\n",
    "x_train = train.loc[:,'0':'127'].as_matrix()\n",
    "x_test = test.loc[:,'0':'127'].as_matrix()\n",
    "y_train = train.loc[:,'ethnicity'].as_matrix()\n",
    "y_test = test.loc[:,'race'].as_matrix()\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train = keras.utils.normalize(x_train)\n",
    "x_test = keras.utils.normalize(x_test)\n",
    "   \n",
    "# 10-fold cross validation\n",
    "folds = list(StratifiedKFold(n_splits=10, shuffle=True, random_state=1).split(x_train, y_train))\n",
    "\n",
    "print(x_train.shape, y_train.shape, 'train shape')\n",
    "print(x_test.shape, y_test.shape,'test shape')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_test_clean = y_test\n",
    "encoder = LabelBinarizer()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.transform(y_test)\n",
    "\n",
    "#if need to figure out relation for the confusion matrix, use inverse_transform\n",
    "cm = np.asarray([[0.82, 0.03, 0.03],[0.02,0.95,0],[0.03,0.02,0.01],[0.04,0,0.91]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define noise layer and models\n",
    "I defined my custom layer for the noise layer. It initializes its weight matrix either as the true noise distribution (confusion matrix) or as a 10x10 identity matrix depending on the init parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns the confusion matrix (the perfectly known noise distribution) in the NoiseLayer initializer\n",
    "def confusion_kernel(shape):\n",
    "    return cm\n",
    "def identity_kernel(shape):\n",
    "    return np.rot90(np.eye(num_classes), 3)\n",
    "\n",
    "#noise layer defined according to Keras functional API\n",
    "class NoiseLayer(Layer):\n",
    "    def __init__(self, output_dim, dynamic=True, initializer=identity_kernel, **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        self.dynamic = dynamic\n",
    "        self.initializer = initializer\n",
    "        super(NoiseLayer, self).__init__(**kwargs)\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        # weight matrix\n",
    "        self.kernel = self.add_weight(name='kernel', \n",
    "                                      shape=input_shape,\n",
    "                                      initializer=self.initializer,\n",
    "                                      trainable=self.dynamic) #change this to false for static weights\n",
    "        super(NoiseLayer, self).build(input_shape)\n",
    "    \n",
    "    #forward pass - vector matrix multiplication of the input and the weights. FIXED for batches\n",
    "    def call(self, x):\n",
    "        return tf.einsum('bn,nm->bn',x, self.kernel)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (1, self.output_dim)\n",
    "    \n",
    "class SoftMaxLayer(Layer):\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        super(SoftMaxLayer, self).__init__(**kwargs)\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        # weight matrix\n",
    "        self.kernel = self.add_weight(name='kernel', \n",
    "                                      shape=input_shape,\n",
    "                                      initializer='uniform',\n",
    "                                      trainable=False) #change this to false for static weights\n",
    "        super(SoftMaxLayer, self).build(input_shape)\n",
    "    \n",
    "    #forward pass - vector matrix multiplication of the input and the weights. FIXED for batches\n",
    "    def call(self, x):\n",
    "        return tf.nn.softmax(x)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (1, self.output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# depth, nodes, initializer, activation, dropout, noise, kernel_init\n",
    "noise_params = []\n",
    "for nodes in [32, 64, 128, 248]:\n",
    "    for dropout in [0.1,0.3, 0.4, 0.6, 0.8]:\n",
    "        for depth in [1,2,3,4,6]:\n",
    "            for activ in [ELU(),LeakyReLU(), keras.layers.Activation(\"relu\"),keras.layers.Activation(\"sigmoid\")]:\n",
    "                for init_func in [\"glorot_uniform\"]:\n",
    "                    for optim in [keras.optimizers.Adadelta()]:\n",
    "                        for noise_init in [identity_kernel, confusion_kernel]:\n",
    "                            noise_params.append({'noise': True, 'dynamic':  True, 'nodes': nodes, 'dropout': dropout, 'depth': depth, 'activation': activ, \"initializer\": init_func, \"optimizer\": optim, 'noise_init': noise_init})\n",
    "\n",
    "static_params = []\n",
    "for nodes in [32, 64, 128, 248]:\n",
    "    for dropout in [0.1,0.3, 0.4, 0.6, 0.8]:\n",
    "        for depth in [1,2,3,4,6]:\n",
    "            for activ in [ELU(),LeakyReLU(), keras.layers.Activation(\"relu\"),keras.layers.Activation(\"sigmoid\")]:\n",
    "                for init_func in [\"glorot_uniform\"]:\n",
    "                    for optim in [keras.optimizers.Adadelta()]:\n",
    "                        for noise_init in [identity_kernel, confusion_kernel]:\n",
    "                            noise_params.append({'noise': True, 'dynamic':  False, 'nodes': nodes, 'dropout': dropout, 'depth': depth, 'activation': activ, \"initializer\": init_func, \"optimizer\": optim, 'noise_init': noise_init})\n",
    "\n",
    "default_params = []\n",
    "for nodes in [32, 64, 128, 248]:\n",
    "    for dropout in [0.1,0.3, 0.4, 0.6, 0.8]:\n",
    "        for depth in [1,2,3,4,6]:\n",
    "            for activ in [ELU(),LeakyReLU(), keras.layers.Activation(\"relu\"),keras.layers.Activation(\"sigmoid\")]:\n",
    "                for init_func in [\"glorot_uniform\"]:\n",
    "                    for optim in [keras.optimizers.Adadelta()]:\n",
    "                        default_params.append({'noise': False, 'dynamic':  False, 'nodes': nodes, 'dropout': dropout, 'depth': depth, 'activation': activ, \"initializer\": init_func, \"optimizer\": optim})\n",
    "\n",
    "noise_params = pd.Series(noise_params).sample(100)                        \n",
    "static_params = pd.Series(static_params).sample(50)                        \n",
    "default_params = pd.Series(default_params).sample(50)                        \n",
    "                        \n",
    "def build_model(param):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(param['nodes']+64, kernel_initializer=param['initializer'], input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(param['activation']())\n",
    "    model.add(Dropout(param['dropout']))\n",
    "    \n",
    "    for i in param['depth']:\n",
    "        model.add(Dense(param['nodes'], kernel_initializer=param['initializer'], input_shape=input_shape))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(param['activation']())\n",
    "        model.add(param['dropout'])\n",
    "        \n",
    "    model.add(Dense(64, kernel_initializer=param['initializer']))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, kernel_initializer=param['initializer'], activation=\"softmax\"))\n",
    "    \n",
    "    # attach noise layer\n",
    "    if (param['noise']):\n",
    "        model.add(NoiseLayer(num_classes, dynamic=param['dynamic'], initializer=param['noise_init']))\n",
    "        model.add(Dropout(0.1))\n",
    "        model.add(SoftMaxLayer(num_classes))\n",
    "\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adadelta(),\n",
    "                  metrics=[keras.metrics.categorical_accuracy])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Default model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for logging in cnn.log\n",
    "print_callback = keras.callbacks.LambdaCallback(\n",
    "        on_epoch_end=lambda epoch,logs: double_log.logger.debug('epoch: '+ str(epoch+1)+ ' logs: '+ str(logs)))\n",
    "\n",
    "best = 0\n",
    "\n",
    "# Testing default moel without noise model attached\n",
    "results_def = {}\n",
    "for h, param in enumerate(default_params):\n",
    "    cvscores = []\n",
    "    for j, (train_idx, val_idx) in enumerate(folds[0:3]):\n",
    "        print(\"===Default - Fold \",j,\" - Param set number \",h,\" ======\")\n",
    "        x_train_cv = x_train[train_idx]\n",
    "        y_train_cv = y_train[train_idx]\n",
    "        x_valid_cv = x_train[val_idx]\n",
    "        y_valid_cv= y_train[val_idx]\n",
    "        \n",
    "        def_model = build_model(param)\n",
    "        def_model.fit(x_train_cv, y_train_cv,\n",
    "                  batch_size=batch_size,\n",
    "                  epochs=epochs,\n",
    "                  verbose=0,\n",
    "                  validation_data=(x_valid_cv, y_valid_cv),\n",
    "                  callbacks=[print_callback])\n",
    "        \n",
    "        pred_def = def_model.predict(x_test, verbose=0)\n",
    "\n",
    "        f1 = f1_score([max(enumerate(i), key=operator.itemgetter(1))[0] for i in pred_def.tolist()], [max(enumerate(i), key=operator.itemgetter(1))[0] for i in y_test.tolist()], average='micro')\n",
    "        results_def.append({\"F1\": f1, \"parameters\": param})\n",
    "        #print('F1-score:', f1, \"\\n===================\")\n",
    "        \n",
    "print(\"\\nAverage model score: %.3f%% (+/- %.3f%%)\\n\" % (np.mean(results_def), np.std(results_def)))\n",
    "for i in results_def:\n",
    "    print(i, '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#build model without the denoising custom layer\n",
    "def build_dnn(param):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(param['nodes']+64, kernel_initializer=param['initializer'], input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(param['activation']())\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "#     if param['deeper']:\n",
    "#         model.add(Dense(param['nodes'], kernel_initializer=param['initializer'], input_shape=input_shape))\n",
    "#         model.add(BatchNormalization())\n",
    "#         model.add(param['activation']())\n",
    "#         model.add(Dropout(0.5))\n",
    "    \n",
    "#     model.add(Dense(param['nodes'], kernel_initializer=param['initializer'], input_shape=input_shape))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(param['activation']())\n",
    "#     model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(param['nodes'], kernel_initializer=param['initializer'], input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(param['activation']())\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(64, kernel_initializer=param['initializer']))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, kernel_initializer=param['initializer'], activation=\"softmax\"))\n",
    "\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adadelta(),\n",
    "                  metrics=[keras.metrics.categorical_accuracy])\n",
    "    return model\n",
    "\n",
    "#build model with denoising layer\n",
    "def build_noisy(trainable, init_func, param):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(param['nodes'], kernel_initializer=param['initializer'], input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(param['activation'])\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "#     if param['deeper']:\n",
    "#         model.add(Dense(param['nodes'], kernel_initializer=param['initializer']))\n",
    "#         model.add(BatchNormalization())\n",
    "#         model.add(param['activation']())\n",
    "#         model.add(Dropout(0.5))\n",
    "    \n",
    "#     if param['deeper']:\n",
    "#         model.add(Dense(param['nodes'], kernel_initializer=param['initializer']))\n",
    "#         model.add(BatchNormalization())\n",
    "#         model.add(param['activation']())\n",
    "#         model.add(Dropout(0.5))\n",
    "    \n",
    "#     model.add(Dense(param['nodes'], kernel_initializer=param['initializer']))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(param['activation']())\n",
    "#     model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(param['nodes'], kernel_initializer=param['initializer']))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(param['activation'])\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(64, kernel_initializer=param['initializer']))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, kernel_initializer=param['initializer'], activation=\"softmax\"))\n",
    "\n",
    "    # attach noise layer\n",
    "    model.add(NoiseLayer(num_classes, dynamic=trainable, initializer=init_func))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(SoftMaxLayer(num_classes))\n",
    "    \n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=param[\"optimizer\"],\n",
    "                  metrics=[keras.metrics.categorical_accuracy])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = []\n",
    "for nodes in [128]:\n",
    "    for deep in [True]:\n",
    "        for do in [ELU(),LeakyReLU(), keras.layers.Activation(\"relu\"),keras.layers.Activation(\"sigmoid\")]:\n",
    "            for ki in [\"glorot_uniform\"]:\n",
    "                for op in [keras.optimizers.Adadelta()]:\n",
    "                    params.append({'nodes': nodes, 'deeper': deep, 'activation': do, \"initializer\": ki, \"optimizer\": op})\n",
    "                \n",
    "# for nodes in [80, 100, 156]:\n",
    "#     for deep in [True]:\n",
    "#         for do in [ELU()]:\n",
    "#             for op in [keras.optimizers.Adadelta()]:\n",
    "#                     params.append({'nodes': nodes, 'deeper': deep, 'activation': do, \"initializer\": ki, \"optimizer\": op})\n",
    "ki = \"glorot_uniform\"\n",
    "for nodes in [128]:\n",
    "    for deep in [True]:\n",
    "        for do in [ELU()]:\n",
    "            for op in [keras.optimizers.Adam()]:\n",
    "                    params.append({'nodes': nodes, 'deeper': deep, 'activation': do, \"initializer\": ki, \"optimizer\": op})\n",
    "len(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run default model 5 times with cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#for logging in cnn.log\n",
    "print_callback = keras.callbacks.LambdaCallback(\n",
    "        on_epoch_end=lambda epoch,logs: double_log.logger.debug('epoch: '+ str(epoch+1)+ ' logs: '+ str(logs)))\n",
    "\n",
    "# Testing default moel without noise model attached\n",
    "results_def = []\n",
    "\n",
    "\n",
    "######################################\n",
    "params = [{'nodes': 64, 'deeper': True, 'activation': ELU(), \"initializer\": \"glorot_uniform\", \"optimizer\": keras.optimizers.Adadelta()}]\n",
    "\n",
    "\n",
    "\n",
    "for h, param in enumerate(params):\n",
    "    for j, (train_idx, val_idx) in enumerate(folds[0:2]):\n",
    "        print(\"===Default - Fold \",j,\" - Training Round \",h,\" ======\")\n",
    "        x_train_cv = x_train[train_idx]\n",
    "        y_train_cv = y_train[train_idx]\n",
    "        x_valid_cv = x_train[val_idx]\n",
    "        y_valid_cv= y_train[val_idx]\n",
    "        \n",
    "        def_model = build_dnn(param)\n",
    "        def_model.fit(x_train_cv, y_train_cv,\n",
    "                  batch_size=batch_size,\n",
    "                  epochs=epochs,\n",
    "                  verbose=0,\n",
    "                  validation_data=(x_valid_cv, y_valid_cv),\n",
    "                  callbacks=[print_callback])\n",
    "        \n",
    "        pred_def = def_model.predict(x_test, verbose=0)\n",
    "\n",
    "        f1 = f1_score([max(enumerate(i), key=operator.itemgetter(1))[0] for i in pred_def.tolist()], [max(enumerate(i), key=operator.itemgetter(1))[0] for i in y_test.tolist()], average='micro')\n",
    "        results_def.append({\"F1\": f1, \"parameters\": param})\n",
    "        #print('F1-score:', f1, \"\\n===================\")\n",
    "        \n",
    "#print(\"\\nAverage model score: %.3f%% (+/- %.3f%%)\" % (np.mean(results_def), np.std(results_def)))\n",
    "for i in results_def:\n",
    "    print(i, '\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run dynamic noise model 5 times with cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Dynamic - Fold  0  - Training Round  0  ======\n",
      "===Dynamic - Fold  1  - Training Round  0  ======\n"
     ]
    }
   ],
   "source": [
    "# DO I NEED THIS? K.set_learning_phase(1)\n",
    "#for logging in cnn.log\n",
    "print_callback = keras.callbacks.LambdaCallback(\n",
    "        on_epoch_end=lambda epoch,logs: double_log.logger.debug('epoch: '+ str(epoch+1)+ ' logs: '+ str(logs)))\n",
    "\n",
    "# Testing default moel without noise model attached\n",
    "results_noise_dyn = []\n",
    "for h,param in enumerate(params):\n",
    "    for j, (train_idx, val_idx) in enumerate(folds[0:2]):\n",
    "        print(\"===Dynamic - Fold \",j,\" - Training Round \",h,\" ======\")\n",
    "        x_train_cv = x_train[train_idx]\n",
    "        y_train_cv = y_train[train_idx]\n",
    "        x_valid_cv = x_train[val_idx]\n",
    "        y_valid_cv= y_train[val_idx]\n",
    "        \n",
    "        dyn_model = build_noisy(True, identity_kernel, param)\n",
    "#         dyn_model.fit(x_train_cv, y_train_cv,\n",
    "#                   batch_size=batch_size,\n",
    "#                   epochs=epochs,\n",
    "#                   verbose=0,\n",
    "#                   validation_data=(x_valid_cv, y_valid_cv),\n",
    "#                   callbacks=[print_callback])\n",
    "        \n",
    "#         #the whole system's output\n",
    "#         pred_dyn = dyn_model.predict(x_test, verbose=0)   \n",
    "#         f1 = f1_score([max(enumerate(i), key=operator.itemgetter(1))[0] for i in pred_dyn.tolist()], [max(enumerate(i), key=operator.itemgetter(1))[0] for i in y_test.tolist()], average='micro')\n",
    "        \n",
    "#         #remove the noise layers to reveal what the base model learnt\n",
    "#         dyn_model2 = Model(dyn_model.input, dyn_model.layers[-4].output)\n",
    "#         pred2_dyn = dyn_model2.predict(x_test, verbose=0, batch_size=10)\n",
    "#         f12 = f1_score([max(enumerate(i), key=operator.itemgetter(1))[0] for i in pred2_dyn.tolist()], [max(enumerate(i), key=operator.itemgetter(1))[0] for i in y_test.tolist()], average='micro')\n",
    "        \n",
    "#         results_noise_dyn.append({\"F1 removed noise\": f12, \"F1 whole\": f1, \"parameters\": param, \"weights\": dyn_model.layers[-3].get_weights()[0]})\n",
    "#         #print('F1-score:', f12, \"Intermediary score: \",f1)\n",
    "#         #print(pd.DataFrame(dyn_model.layers[-2].get_weights()[0]),\"\\n===================\")\n",
    "        \n",
    "#print(\"\\nAverage score: %.2f%% (+/- %.2f%%)\" % (np.mean(results_noise_dyn), np.std(results_noise_dyn)))\n",
    "#print(\"\\nAverage Intermediary model score: %.2f%% (+/- %.2f%%)\" % (np.mean(results_noise_dyn_int), np.std(results_noise_dyn_int)))\n",
    "for i in results_noise_dyn:\n",
    "    print(i, '\\n\\n')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00799287  0.04571648  0.15867135  0.09491929  0.0096664   0.19281764\n",
      "  0.0100825  -0.04140904 -0.01566594 -0.00083109  0.0852031  -0.05859995\n",
      " -0.00312085  0.03822699  0.11992753 -0.05146921  0.02214412  0.1672824\n",
      " -0.05505125 -0.1344187   0.14127165 -0.09186476  0.02150905  0.13825987\n",
      "  0.1957287  -0.20598537 -0.10196396 -0.02657196 -0.05300907 -0.00548683\n",
      "  0.18350196 -0.09354842 -0.06487526  0.06295002  0.07886887  0.06597852\n",
      " -0.14758076 -0.09496702 -0.01598781 -0.06822222  0.02206304 -0.00749762\n",
      " -0.0170685   0.00970518 -0.00638292 -0.14162707 -0.04309015 -0.00417323\n",
      " -0.10773767 -0.07976305  0.07095603 -0.05857699  0.01589625 -0.09740327\n",
      " -0.05242364  0.11549183 -0.09588418  0.14004028  0.02608029 -0.05594381\n",
      " -0.05424505  0.0841369  -0.00031817 -0.14596382  0.1212517   0.1347408\n",
      " -0.02282001  0.01101747 -0.22255619  0.20463571  0.08626571  0.10530165\n",
      " -0.03275525 -0.17383835 -0.07188705 -0.00798718  0.00054002 -0.06647094\n",
      " -0.00266103  0.02219233 -0.14252867 -0.04111485  0.033516   -0.08441863\n",
      " -0.13853045 -0.01305619  0.0215146  -0.0983611  -0.07298588  0.06160895\n",
      "  0.00964909 -0.11085632  0.05797494 -0.02079882 -0.02053078  0.0160589\n",
      " -0.09627756 -0.00669324 -0.06375274  0.09188132  0.04872002  0.05726852\n",
      " -0.05023991 -0.05187875  0.0754972   0.10298497  0.02472185 -0.09409607\n",
      "  0.01581819 -0.09377741 -0.05906137  0.00147768  0.00993312  0.00048185\n",
      "  0.14739908  0.02425448 -0.07055076  0.08683231  0.05359123  0.12680066\n",
      "  0.03780453 -0.13104478 -0.13660634  0.01508993  0.11995895  0.10502732\n",
      "  0.09169927  0.01033412]\n"
     ]
    }
   ],
   "source": [
    "import pydot\n",
    "from keras.utils import plot_model\n",
    "plot_model(dyn_model, to_file='model.png', show_shapes=True, show_layer_names=False)\n",
    "\n",
    "print(x_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ 0.00799287, 0.04571648, 0.15867135, 0.09491929,\n",
    " 0.0096664, 0.19281764, 0.0100825, -0.04140904,\n",
    " -0.01566594 -0.00083109, 0.0852031, -0.05859995\n",
    "-0.00312085, 0.03822699, 0.11992753 -0.05146921,\n",
    " 0.02214412, 0.1672824 -0.05505125 -0.1344187,\n",
    " 0.14127165 -0.09186476, 0.02150905, 0.13825987,\n",
    "0.1957287, -0.20598537 -0.10196396 -0.02657196\n",
    " -0.05300907 -0.00548683, 0.18350196 -0.09354842\n",
    "-0.06487526, 0.06295002, 0.07886887, 0.06597852\n",
    " -0.14758076 -0.09496702 -0.01598781 -0.06822222,\n",
    "0.02206304 -0.00749762 -0.0170685, 0.00970518\n",
    " -0.00638292 -0.14162707 -0.04309015 -0.00417323\n",
    "-0.10773767 -0.07976305, 0.07095603 -0.05857699,\n",
    " 0.01589625 -0.09740327 -0.05242364, 0.11549183\n",
    "-0.09588418, 0.14004028, 0.02608029 -0.05594381\n",
    " -0.05424505, 0.0841369, -0.00031817 -0.14596382,\n",
    "0.1212517, 0.1347408 -0.02282001, 0.01101747\n",
    " -0.22255619, 0.20463571, 0.08626571, 0.10530165\n",
    "-0.03275525 -0.17383835 -0.07188705 -0.00798718,\n",
    " 0.00054002 -0.06647094 -0.00266103, 0.02219233\n",
    "-0.14252867 -0.04111485, 0.033516,-0.08441863\n",
    " -0.13853045 -0.01305619, 0.0215146, -0.0983611,\n",
    "-0.07298588, 0.06160895, 0.00964909 -0.11085632,\n",
    " 0.05797494 -0.02079882 -0.02053078, 0.0160589\n",
    "-0.09627756 -0.00669324 -0.06375274, 0.09188132,\n",
    " 0.04872002, 0.05726852 -0.05023991 -0.05187875,\n",
    "0.0754972, 0.10298497, 0.02472185 -0.09409607,\n",
    " 0.01581819 -0.09377741 -0.05906137, 0.00147768,\n",
    "0.00993312, 0.00048185, 0.14739908, 0.02425448 \n",
    "-0.07055076, 0.08683231, 0.05359123, 0.12680066,\n",
    " 0.03780453 -0.13104478 -0.13660634, 0.01508993,\n",
    "0.11995895, 0.10502732, 0.09169927, 0.01033412]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run static noise model 5 times with cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# DO I NEED THIS? K.set_learning_phase(1)\n",
    "#for logging in cnn.log\n",
    "print_callback = keras.callbacks.LambdaCallback(\n",
    "        on_epoch_end=lambda epoch,logs: double_log.logger.debug('epoch: '+ str(epoch+1)+ ' logs: '+ str(logs)))\n",
    "\n",
    "# Testing default moel without noise model attached\n",
    "results_noise_sta = []\n",
    "for param in params:\n",
    "    for j, (train_idx, val_idx) in enumerate(folds[0:2]):\n",
    "        print(\"===Static - Fold \",j,\" - Training Round \",h,\" ======\")\n",
    "        x_train_cv = x_train[train_idx]\n",
    "        y_train_cv = y_train[train_idx]\n",
    "        x_valid_cv = x_train[val_idx]\n",
    "        y_valid_cv= y_train[val_idx]\n",
    "        \n",
    "        sta_model = build_noisy(False, confusion_kernel, param)\n",
    "        sta_model.fit(x_train_cv, y_train_cv,\n",
    "                  batch_size=batch_size,\n",
    "                  epochs=epochs,\n",
    "                  verbose=0,\n",
    "                  validation_data=(x_valid_cv, y_valid_cv),\n",
    "                  callbacks=[print_callback])\n",
    "        \n",
    "        #the whole system's output\n",
    "        pred_sta = sta_model.predict(x_test, verbose=0)   \n",
    "        f1 = f1_score([max(enumerate(i), key=operator.itemgetter(1))[0] for i in pred_sta.tolist()], [max(enumerate(i), key=operator.itemgetter(1))[0] for i in y_test.tolist()], average='micro')\n",
    "        \n",
    "        #remove the noise layers to reveal what the base model learnt\n",
    "        sta_model2 = Model(sta_model.input, sta_model.layers[-4].output)\n",
    "        pred2_sta = sta_model2.predict(x_test, verbose=0, batch_size=10)\n",
    "        f12 = f1_score([max(enumerate(i), key=operator.itemgetter(1))[0] for i in pred2_sta.tolist()], [max(enumerate(i), key=operator.itemgetter(1))[0] for i in y_test.tolist()], average='micro')\n",
    "        \n",
    "        results_noise_sta.append({\"F1 removed noise\": f12, \"F1 whole\": f1, \"parameters\": param})\n",
    "        #print('F1-score:', f12, \"Intermediary score: \",f1)\n",
    "        #print(pd.DataFrame(model.layers[-2].get_weights()[0]),\"\\n===================\")\n",
    "        \n",
    "#print(\"\\nAverage score: %.2f%% (+/- %.2f%%)\" % (np.mean(results_noise_sta), np.std(results_noise_sta)))\n",
    "#print(\"\\nAverage Intermediary model score: %.2f%% (+/- %.2f%%)\" % (np.mean(results_noise_sta_int), np.std(results_noise_sta_int)))\n",
    "for i in results_noise_sta:\n",
    "    print(i, '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== DEFAULT BASE MODEL ======\n",
      "{'F1': 0.7652082512153462, 'parameters': {'nodes': 64, 'activation': <class 'keras.layers.advanced_activations.LeakyReLU'>, 'deeper': True, 'initializer': 'he_normal'}} \n",
      "\n",
      "\n",
      "{'F1': 0.7209302325581395, 'parameters': {'nodes': 64, 'activation': <class 'keras.layers.advanced_activations.LeakyReLU'>, 'deeper': True, 'initializer': 'he_normal'}} \n",
      "\n",
      "\n",
      "{'F1': 0.7368282748653265, 'parameters': {'nodes': 64, 'activation': <class 'keras.layers.advanced_activations.LeakyReLU'>, 'deeper': True, 'initializer': 'glorot_uniform'}} \n",
      "\n",
      "\n",
      "{'F1': 0.7223755091315202, 'parameters': {'nodes': 64, 'activation': <class 'keras.layers.advanced_activations.LeakyReLU'>, 'deeper': True, 'initializer': 'glorot_uniform'}} \n",
      "\n",
      "\n",
      "{'F1': 0.7361713309683353, 'parameters': {'nodes': 64, 'activation': <class 'keras.layers.advanced_activations.ELU'>, 'deeper': True, 'initializer': 'he_normal'}} \n",
      "\n",
      "\n",
      "{'F1': 0.7027985810011825, 'parameters': {'nodes': 64, 'activation': <class 'keras.layers.advanced_activations.ELU'>, 'deeper': True, 'initializer': 'he_normal'}} \n",
      "\n",
      "\n",
      "{'F1': 0.7483904874523716, 'parameters': {'nodes': 64, 'activation': <class 'keras.layers.advanced_activations.ELU'>, 'deeper': True, 'initializer': 'glorot_uniform'}} \n",
      "\n",
      "\n",
      "{'F1': 0.7223755091315202, 'parameters': {'nodes': 64, 'activation': <class 'keras.layers.advanced_activations.ELU'>, 'deeper': True, 'initializer': 'glorot_uniform'}} \n",
      "\n",
      "\n",
      "{'F1': 0.7167257916173959, 'parameters': {'nodes': 64, 'activation': <class 'keras.layers.advanced_activations.LeakyReLU'>, 'deeper': False, 'initializer': 'he_normal'}} \n",
      "\n",
      "\n",
      "{'F1': 0.7314413349099987, 'parameters': {'nodes': 64, 'activation': <class 'keras.layers.advanced_activations.LeakyReLU'>, 'deeper': False, 'initializer': 'he_normal'}} \n",
      "\n",
      "\n",
      "{'F1': 0.7390618841150965, 'parameters': {'nodes': 64, 'activation': <class 'keras.layers.advanced_activations.LeakyReLU'>, 'deeper': False, 'initializer': 'glorot_uniform'}} \n",
      "\n",
      "\n",
      "{'F1': 0.6855866509000131, 'parameters': {'nodes': 64, 'activation': <class 'keras.layers.advanced_activations.LeakyReLU'>, 'deeper': False, 'initializer': 'glorot_uniform'}} \n",
      "\n",
      "\n",
      "{'F1': 0.7342004992773618, 'parameters': {'nodes': 64, 'activation': <class 'keras.layers.advanced_activations.ELU'>, 'deeper': False, 'initializer': 'he_normal'}} \n",
      "\n",
      "\n",
      "{'F1': 0.735908553409539, 'parameters': {'nodes': 64, 'activation': <class 'keras.layers.advanced_activations.ELU'>, 'deeper': False, 'initializer': 'he_normal'}} \n",
      "\n",
      "\n",
      "{'F1': 0.7140980160294311, 'parameters': {'nodes': 64, 'activation': <class 'keras.layers.advanced_activations.ELU'>, 'deeper': False, 'initializer': 'glorot_uniform'}} \n",
      "\n",
      "\n",
      "{'F1': 0.7356457758507422, 'parameters': {'nodes': 64, 'activation': <class 'keras.layers.advanced_activations.ELU'>, 'deeper': False, 'initializer': 'glorot_uniform'}} \n",
      "\n",
      "\n",
      "{'F1': 0.7313099461306004, 'parameters': {'nodes': 128, 'activation': <class 'keras.layers.advanced_activations.LeakyReLU'>, 'deeper': True, 'initializer': 'he_normal'}} \n",
      "\n",
      "\n",
      "{'F1': 0.7250032847194848, 'parameters': {'nodes': 128, 'activation': <class 'keras.layers.advanced_activations.LeakyReLU'>, 'deeper': True, 'initializer': 'he_normal'}} \n",
      "\n",
      "\n",
      "{'F1': 0.7294705032190251, 'parameters': {'nodes': 128, 'activation': <class 'keras.layers.advanced_activations.LeakyReLU'>, 'deeper': True, 'initializer': 'glorot_uniform'}} \n",
      "\n",
      "\n",
      "{'F1': 0.7393246616738931, 'parameters': {'nodes': 128, 'activation': <class 'keras.layers.advanced_activations.LeakyReLU'>, 'deeper': True, 'initializer': 'glorot_uniform'}} \n",
      "\n",
      "\n",
      "{'F1': 0.7420838260412561, 'parameters': {'nodes': 128, 'activation': <class 'keras.layers.advanced_activations.ELU'>, 'deeper': True, 'initializer': 'he_normal'}} \n",
      "\n",
      "\n",
      "{'F1': 0.728288004204441, 'parameters': {'nodes': 128, 'activation': <class 'keras.layers.advanced_activations.ELU'>, 'deeper': True, 'initializer': 'he_normal'}} \n",
      "\n",
      "\n",
      "{'F1': 0.7339377217185652, 'parameters': {'nodes': 128, 'activation': <class 'keras.layers.advanced_activations.ELU'>, 'deeper': True, 'initializer': 'glorot_uniform'}} \n",
      "\n",
      "\n",
      "{'F1': 0.7225068979109183, 'parameters': {'nodes': 128, 'activation': <class 'keras.layers.advanced_activations.ELU'>, 'deeper': True, 'initializer': 'glorot_uniform'}} \n",
      "\n",
      "\n",
      "{'F1': 0.7465510445407962, 'parameters': {'nodes': 128, 'activation': <class 'keras.layers.advanced_activations.LeakyReLU'>, 'deeper': False, 'initializer': 'he_normal'}} \n",
      "\n",
      "\n",
      "{'F1': 0.7263171725134675, 'parameters': {'nodes': 128, 'activation': <class 'keras.layers.advanced_activations.LeakyReLU'>, 'deeper': False, 'initializer': 'he_normal'}} \n",
      "\n",
      "\n",
      "{'F1': 0.6905794245171463, 'parameters': {'nodes': 128, 'activation': <class 'keras.layers.advanced_activations.LeakyReLU'>, 'deeper': False, 'initializer': 'glorot_uniform'}} \n",
      "\n",
      "\n",
      "{'F1': 0.7289449481014323, 'parameters': {'nodes': 128, 'activation': <class 'keras.layers.advanced_activations.LeakyReLU'>, 'deeper': False, 'initializer': 'glorot_uniform'}} \n",
      "\n",
      "\n",
      "{'F1': 0.7264485612928656, 'parameters': {'nodes': 128, 'activation': <class 'keras.layers.advanced_activations.ELU'>, 'deeper': False, 'initializer': 'he_normal'}} \n",
      "\n",
      "\n",
      "{'F1': 0.7140980160294311, 'parameters': {'nodes': 128, 'activation': <class 'keras.layers.advanced_activations.ELU'>, 'deeper': False, 'initializer': 'he_normal'}} \n",
      "\n",
      "\n",
      "{'F1': 0.7328866114833793, 'parameters': {'nodes': 128, 'activation': <class 'keras.layers.advanced_activations.ELU'>, 'deeper': False, 'initializer': 'glorot_uniform'}} \n",
      "\n",
      "\n",
      "{'F1': 0.7285507817632374, 'parameters': {'nodes': 128, 'activation': <class 'keras.layers.advanced_activations.ELU'>, 'deeper': False, 'initializer': 'glorot_uniform'}} \n",
      "\n",
      "\n",
      "{'F1': 0.7280252266456445, 'parameters': {'nodes': 164, 'activation': <class 'keras.layers.advanced_activations.LeakyReLU'>, 'deeper': True, 'initializer': 'he_normal'}} \n",
      "\n",
      "\n",
      "{'F1': 0.7389304953356983, 'parameters': {'nodes': 164, 'activation': <class 'keras.layers.advanced_activations.LeakyReLU'>, 'deeper': True, 'initializer': 'he_normal'}} \n",
      "\n",
      "\n",
      "{'F1': 0.7255288398370779, 'parameters': {'nodes': 164, 'activation': <class 'keras.layers.advanced_activations.LeakyReLU'>, 'deeper': True, 'initializer': 'glorot_uniform'}} \n",
      "\n",
      "\n",
      "{'F1': 0.7268427276310603, 'parameters': {'nodes': 164, 'activation': <class 'keras.layers.advanced_activations.LeakyReLU'>, 'deeper': True, 'initializer': 'glorot_uniform'}} \n",
      "\n",
      "\n",
      "{'F1': 0.73433188805676, 'parameters': {'nodes': 164, 'activation': <class 'keras.layers.advanced_activations.ELU'>, 'deeper': True, 'initializer': 'he_normal'}} \n",
      "\n",
      "\n",
      "{'F1': 0.7468138220995926, 'parameters': {'nodes': 164, 'activation': <class 'keras.layers.advanced_activations.ELU'>, 'deeper': True, 'initializer': 'he_normal'}} \n",
      "\n",
      "\n",
      "{'F1': 0.73656549730653, 'parameters': {'nodes': 164, 'activation': <class 'keras.layers.advanced_activations.ELU'>, 'deeper': True, 'initializer': 'glorot_uniform'}} \n",
      "\n",
      "\n",
      "{'F1': 0.7037183024569702, 'parameters': {'nodes': 164, 'activation': <class 'keras.layers.advanced_activations.ELU'>, 'deeper': True, 'initializer': 'glorot_uniform'}} \n",
      "\n",
      "\n",
      "{'F1': 0.7357771646301405, 'parameters': {'nodes': 164, 'activation': <class 'keras.layers.advanced_activations.LeakyReLU'>, 'deeper': False, 'initializer': 'he_normal'}} \n",
      "\n",
      "\n",
      "{'F1': 0.7177769018525818, 'parameters': {'nodes': 164, 'activation': <class 'keras.layers.advanced_activations.LeakyReLU'>, 'deeper': False, 'initializer': 'he_normal'}} \n",
      "\n",
      "\n",
      "{'F1': 0.731572723689397, 'parameters': {'nodes': 164, 'activation': <class 'keras.layers.advanced_activations.LeakyReLU'>, 'deeper': False, 'initializer': 'glorot_uniform'}} \n",
      "\n",
      "\n",
      "{'F1': 0.7119957955590593, 'parameters': {'nodes': 164, 'activation': <class 'keras.layers.advanced_activations.LeakyReLU'>, 'deeper': False, 'initializer': 'glorot_uniform'}} \n",
      "\n",
      "\n",
      "{'F1': 0.6703455524898174, 'parameters': {'nodes': 164, 'activation': <class 'keras.layers.advanced_activations.ELU'>, 'deeper': False, 'initializer': 'he_normal'}} \n",
      "\n",
      "\n",
      "{'F1': 0.7100249638680857, 'parameters': {'nodes': 164, 'activation': <class 'keras.layers.advanced_activations.ELU'>, 'deeper': False, 'initializer': 'he_normal'}} \n",
      "\n",
      "\n",
      "{'F1': 0.7225068979109183, 'parameters': {'nodes': 164, 'activation': <class 'keras.layers.advanced_activations.ELU'>, 'deeper': False, 'initializer': 'glorot_uniform'}} \n",
      "\n",
      "\n",
      "{'F1': 0.7267113388516621, 'parameters': {'nodes': 164, 'activation': <class 'keras.layers.advanced_activations.ELU'>, 'deeper': False, 'initializer': 'glorot_uniform'}} \n",
      "\n",
      "\n",
      "\n",
      "===== DYNAMIC NOISE MODEL ======\n",
      "{'F1 whole': 0.7554854815398765, 'weights': array([[0.26467323, 0.26467323, 0.26467323, 1.2646677 ],\n",
      "       [0.44881555, 0.44881555, 1.4488182 , 0.44881555],\n",
      "       [0.5339014 , 1.5339073 , 0.5339014 , 0.5339014 ],\n",
      "       [1.2562531 , 0.25624695, 0.25624695, 0.25624695]], dtype=float32), 'F1 removed noise': 0.7904348968598081, 'parameters': {'nodes': 64, 'activation': <class 'keras.layers.advanced_activations.LeakyReLU'>, 'deeper': True, 'initializer': 'he_normal'}} \n",
      "\n",
      "\n",
      "{'F1 whole': 0.7181710681907765, 'weights': array([[0.2515122 , 0.2515122 , 0.2515122 , 1.2515056 ],\n",
      "       [0.44334498, 0.44334498, 1.4433585 , 0.44334498],\n",
      "       [0.56737965, 1.5673839 , 0.56737965, 0.56737965],\n",
      "       [1.2504761 , 0.25047   , 0.25047   , 0.25047   ]], dtype=float32), 'F1 removed noise': 0.7860990671396663, 'parameters': {'nodes': 64, 'activation': <class 'keras.layers.advanced_activations.LeakyReLU'>, 'deeper': True, 'initializer': 'he_normal'}} \n",
      "\n",
      "\n",
      "{'F1 whole': 0.711338851662068, 'weights': array([[0.24406974, 0.24406974, 0.24406974, 1.2440816 ],\n",
      "       [0.44358715, 0.44358715, 1.4435805 , 0.44358715],\n",
      "       [0.5588617 , 1.558851  , 0.5588617 , 0.5588617 ],\n",
      "       [1.2666014 , 0.26657686, 0.26657686, 0.26657686]], dtype=float32), 'F1 removed noise': 0.7971357246091184, 'parameters': {'nodes': 64, 'activation': <class 'keras.layers.advanced_activations.LeakyReLU'>, 'deeper': True, 'initializer': 'glorot_uniform'}} \n",
      "\n",
      "\n",
      "{'F1 whole': 0.7290763368808304, 'weights': array([[0.25672933, 0.25672933, 0.25672933, 1.2567223 ],\n",
      "       [0.457513  , 0.457513  , 1.4575084 , 0.457513  ],\n",
      "       [0.54199064, 1.5419796 , 0.54199064, 0.54199064],\n",
      "       [1.2566159 , 0.25661397, 0.25661397, 0.25661397]], dtype=float32), 'F1 removed noise': 0.8000262777558796, 'parameters': {'nodes': 64, 'activation': <class 'keras.layers.advanced_activations.LeakyReLU'>, 'deeper': True, 'initializer': 'glorot_uniform'}} \n",
      "\n",
      "\n",
      "{'F1 whole': 0.7248718959400868, 'weights': array([[0.2777939 , 0.2777939 , 0.2777939 , 1.2777938 ],\n",
      "       [0.41875577, 0.41875577, 1.4187673 , 0.41875577],\n",
      "       [0.51934177, 1.519347  , 0.51934177, 0.51934177],\n",
      "       [1.25685   , 0.25686613, 0.25686613, 0.25686613]], dtype=float32), 'F1 removed noise': 0.7899093417422153, 'parameters': {'nodes': 64, 'activation': <class 'keras.layers.advanced_activations.ELU'>, 'deeper': True, 'initializer': 'he_normal'}} \n",
      "\n",
      "\n",
      "{'F1 whole': 0.7037183024569702, 'weights': array([[0.27182156, 0.27182156, 0.27182156, 1.2718344 ],\n",
      "       [0.40748876, 0.40748876, 1.4074801 , 0.40748876],\n",
      "       [0.54450786, 1.5445043 , 0.54450786, 0.54450786],\n",
      "       [1.2607617 , 0.26076525, 0.26076525, 0.26076525]], dtype=float32), 'F1 removed noise': 0.7876757324924452, 'parameters': {'nodes': 64, 'activation': <class 'keras.layers.advanced_activations.ELU'>, 'deeper': True, 'initializer': 'he_normal'}} \n",
      "\n",
      "\n",
      "{'F1 whole': 0.6682433320194455, 'weights': array([[0.26371288, 0.26371288, 0.26371288, 1.2637116 ],\n",
      "       [0.42124426, 0.42124426, 1.4212412 , 0.42124426],\n",
      "       [0.53964454, 1.539663  , 0.53964454, 0.53964454],\n",
      "       [1.2671669 , 0.26716226, 0.26716226, 0.26716226]], dtype=float32), 'F1 removed noise': 0.7888582315070293, 'parameters': {'nodes': 64, 'activation': <class 'keras.layers.advanced_activations.ELU'>, 'deeper': True, 'initializer': 'glorot_uniform'}} \n",
      "\n",
      "\n",
      "{'F1 whole': 0.7433977138352384, 'weights': array([[0.2719342 , 0.2719342 , 0.2719342 , 1.2719252 ],\n",
      "       [0.42470062, 0.42470062, 1.4246832 , 0.42470062],\n",
      "       [0.54250586, 1.5425087 , 0.54250586, 0.54250586],\n",
      "       [1.2571448 , 0.25712714, 0.25712714, 0.25712714]], dtype=float32), 'F1 removed noise': 0.8000262777558796, 'parameters': {'nodes': 64, 'activation': <class 'keras.layers.advanced_activations.ELU'>, 'deeper': True, 'initializer': 'glorot_uniform'}} \n",
      "\n",
      "\n",
      "{'F1 whole': 0.7181710681907765, 'weights': array([[0.26688623, 0.26688623, 0.26688623, 1.2668902 ],\n",
      "       [0.46028003, 0.46028003, 1.4602842 , 0.46028003],\n",
      "       [0.53790325, 1.537908  , 0.53790325, 0.53790325],\n",
      "       [1.2564044 , 0.2564013 , 0.2564013 , 0.2564013 ]], dtype=float32), 'F1 removed noise': 0.7904348968598081, 'parameters': {'nodes': 64, 'activation': <class 'keras.layers.advanced_activations.LeakyReLU'>, 'deeper': False, 'initializer': 'he_normal'}} \n",
      "\n",
      "\n",
      "{'F1 whole': 0.7229010642491132, 'weights': array([[0.25587747, 0.25587747, 0.25587747, 1.2558774 ],\n",
      "       [0.45215136, 0.45215136, 1.4521563 , 0.45215136],\n",
      "       [0.5143483 , 1.5143455 , 0.5143483 , 0.5143483 ],\n",
      "       [1.2628678 , 0.26287997, 0.26287997, 0.26287997]], dtype=float32), 'F1 removed noise': 0.7882012876100382, 'parameters': {'nodes': 64, 'activation': <class 'keras.layers.advanced_activations.LeakyReLU'>, 'deeper': False, 'initializer': 'he_normal'}} \n",
      "\n",
      "\n",
      "{'F1 whole': 0.7280252266456445, 'weights': array([[0.25019845, 0.25019845, 0.25019845, 1.2501898 ],\n",
      "       [0.45042267, 0.45042267, 1.4504476 , 0.45042267],\n",
      "       [0.5551791 , 1.5551775 , 0.5551791 , 0.5551791 ],\n",
      "       [1.26573   , 0.26573294, 0.26573294, 0.26573294]], dtype=float32), 'F1 removed noise': 0.7973985021679149, 'parameters': {'nodes': 64, 'activation': <class 'keras.layers.advanced_activations.LeakyReLU'>, 'deeper': False, 'initializer': 'glorot_uniform'}} \n",
      "\n",
      "\n",
      "{'F1 whole': 0.7004335829720142, 'weights': array([[0.27211264, 0.27211264, 0.27211264, 1.2721119 ],\n",
      "       [0.44169798, 0.44169798, 1.4417077 , 0.44169798],\n",
      "       [0.48395592, 1.4839662 , 0.48395592, 0.48395592],\n",
      "       [1.26314   , 0.26314518, 0.26314518, 0.26314518]], dtype=float32), 'F1 removed noise': 0.7761135199054001, 'parameters': {'nodes': 64, 'activation': <class 'keras.layers.advanced_activations.LeakyReLU'>, 'deeper': False, 'initializer': 'glorot_uniform'}} \n",
      "\n",
      "\n",
      "{'F1 whole': 0.7257916173958744, 'weights': array([[0.26452428, 0.26452428, 0.26452428, 1.264527  ],\n",
      "       [0.42812303, 0.42812303, 1.428114  , 0.42812303],\n",
      "       [0.5521684 , 1.5521835 , 0.5521684 , 0.5521684 ],\n",
      "       [1.2702438 , 0.27023867, 0.27023867, 0.27023867]], dtype=float32), 'F1 removed noise': 0.7921429509919853, 'parameters': {'nodes': 64, 'activation': <class 'keras.layers.advanced_activations.ELU'>, 'deeper': False, 'initializer': 'he_normal'}} \n",
      "\n",
      "\n",
      "{'F1 whole': 0.7077913546183154, 'weights': array([[0.27102628, 0.27102628, 0.27102628, 1.2710286 ],\n",
      "       [0.41690308, 0.41690308, 1.4169029 , 0.41690308],\n",
      "       [0.53206193, 1.5320686 , 0.53206193, 0.53206193],\n",
      "       [1.2746181 , 0.27461547, 0.27461547, 0.27461547]], dtype=float32), 'F1 removed noise': 0.7892523978452239, 'parameters': {'nodes': 64, 'activation': <class 'keras.layers.advanced_activations.ELU'>, 'deeper': False, 'initializer': 'he_normal'}} \n",
      "\n",
      "\n",
      "{'F1 whole': 0.7081855209565103, 'weights': array([[0.2703733 , 0.2703733 , 0.2703733 , 1.2703886 ],\n",
      "       [0.43697968, 0.43697968, 1.4369767 , 0.43697968],\n",
      "       [0.5583556 , 1.5583649 , 0.5583556 , 0.5583556 ],\n",
      "       [1.2611368 , 0.26115188, 0.26115188, 0.26115188]], dtype=float32), 'F1 removed noise': 0.7954276704769413, 'parameters': {'nodes': 64, 'activation': <class 'keras.layers.advanced_activations.ELU'>, 'deeper': False, 'initializer': 'glorot_uniform'}} \n",
      "\n",
      "\n",
      "{'F1 whole': 0.7477335435553804, 'weights': array([[0.27297395, 0.27297395, 0.27297395, 1.2729592 ],\n",
      "       [0.44741297, 0.44741297, 1.4474105 , 0.44741297],\n",
      "       [0.49890366, 1.4989133 , 0.49890366, 0.49890366],\n",
      "       [1.2656075 , 0.26560962, 0.26560962, 0.26560962]], dtype=float32), 'F1 removed noise': 0.7983182236237026, 'parameters': {'nodes': 64, 'activation': <class 'keras.layers.advanced_activations.ELU'>, 'deeper': False, 'initializer': 'glorot_uniform'}} \n",
      "\n",
      "\n",
      "{'F1 whole': 0.7472079884377874, 'weights': array([[0.2633816 , 0.2633816 , 0.2633816 , 1.2633816 ],\n",
      "       [0.46684805, 0.46684805, 1.466855  , 0.46684805],\n",
      "       [0.5470814 , 1.5470772 , 0.5470814 , 0.5470814 ],\n",
      "       [1.266943  , 0.26693964, 0.26693964, 0.26693964]], dtype=float32), 'F1 removed noise': 0.7979240572855079, 'parameters': {'nodes': 128, 'activation': <class 'keras.layers.advanced_activations.LeakyReLU'>, 'deeper': True, 'initializer': 'he_normal'}} \n",
      "\n",
      "\n",
      "{'F1 whole': 0.7368282748653265, 'weights': array([[0.27839574, 0.27839574, 0.27839574, 1.2783985 ],\n",
      "       [0.4617599 , 0.4617599 , 1.4617578 , 0.4617599 ],\n",
      "       [0.52668697, 1.5266767 , 0.52668697, 0.52668697],\n",
      "       [1.271679  , 0.27168018, 0.27168018, 0.27168018]], dtype=float32), 'F1 removed noise': 0.7879385100512416, 'parameters': {'nodes': 128, 'activation': <class 'keras.layers.advanced_activations.LeakyReLU'>, 'deeper': True, 'initializer': 'he_normal'}} \n",
      "\n",
      "\n",
      "{'F1 whole': 0.7265799500722638, 'weights': array([[0.26711145, 0.26711145, 0.26711145, 1.2671043 ],\n",
      "       [0.48353687, 0.48353687, 1.483528  , 0.48353687],\n",
      "       [0.5421461 , 1.5421478 , 0.5421461 , 0.5421461 ],\n",
      "       [1.2685391 , 0.26852608, 0.26852608, 0.26852608]], dtype=float32), 'F1 removed noise': 0.7900407305216135, 'parameters': {'nodes': 128, 'activation': <class 'keras.layers.advanced_activations.LeakyReLU'>, 'deeper': True, 'initializer': 'glorot_uniform'}} \n",
      "\n",
      "\n",
      "{'F1 whole': 0.702535803442386, 'weights': array([[0.2637802 , 0.2637802 , 0.2637802 , 1.2637852 ],\n",
      "       [0.47572938, 0.47572938, 1.4757272 , 0.47572938],\n",
      "       [0.5559065 , 1.5559125 , 0.5559065 , 0.5559065 ],\n",
      "       [1.2605221 , 0.26052046, 0.26052046, 0.26052046]], dtype=float32), 'F1 removed noise': 0.7920115622125871, 'parameters': {'nodes': 128, 'activation': <class 'keras.layers.advanced_activations.LeakyReLU'>, 'deeper': True, 'initializer': 'glorot_uniform'}} \n",
      "\n",
      "\n",
      "{'F1 whole': 0.6991196951780317, 'weights': array([[0.28444538, 0.28444538, 0.28444538, 1.284447  ],\n",
      "       [0.44347018, 0.44347018, 1.4434615 , 0.44347018],\n",
      "       [0.54550964, 1.5455163 , 0.54550964, 0.54550964],\n",
      "       [1.264     , 0.26399267, 0.26399267, 0.26399267]], dtype=float32), 'F1 removed noise': 0.7875443437130469, 'parameters': {'nodes': 128, 'activation': <class 'keras.layers.advanced_activations.ELU'>, 'deeper': True, 'initializer': 'he_normal'}} \n",
      "\n",
      "\n",
      "{'F1 whole': 0.735908553409539, 'weights': array([[0.2867512 , 0.2867512 , 0.2867512 , 1.2867441 ],\n",
      "       [0.44225323, 0.44225323, 1.4422361 , 0.44225323],\n",
      "       [0.53287584, 1.5328866 , 0.53287584, 0.53287584],\n",
      "       [1.2797065 , 0.27969486, 0.27969486, 0.27969486]], dtype=float32), 'F1 removed noise': 0.7939823939035606, 'parameters': {'nodes': 128, 'activation': <class 'keras.layers.advanced_activations.ELU'>, 'deeper': True, 'initializer': 'he_normal'}} \n",
      "\n",
      "\n",
      "{'F1 whole': 0.7502299303639469, 'weights': array([[0.29652014, 0.29652014, 0.29652014, 1.2965182 ],\n",
      "       [0.45083043, 0.45083043, 1.4508511 , 0.45083043],\n",
      "       [0.5359442 , 1.5359561 , 0.5359442 , 0.5359442 ],\n",
      "       [1.2731664 , 0.27317685, 0.27317685, 0.27317685]], dtype=float32), 'F1 removed noise': 0.79253711733018, 'parameters': {'nodes': 128, 'activation': <class 'keras.layers.advanced_activations.ELU'>, 'deeper': True, 'initializer': 'glorot_uniform'}} \n",
      "\n",
      "\n",
      "{'F1 whole': 0.7197477335435554, 'weights': array([[0.28696516, 0.28696516, 0.28696516, 1.2869687 ],\n",
      "       [0.4405231 , 0.4405231 , 1.4405297 , 0.4405231 ],\n",
      "       [0.52556586, 1.5255524 , 0.52556586, 0.52556586],\n",
      "       [1.2794278 , 0.27941108, 0.27941108, 0.27941108]], dtype=float32), 'F1 removed noise': 0.7836026803310996, 'parameters': {'nodes': 128, 'activation': <class 'keras.layers.advanced_activations.ELU'>, 'deeper': True, 'initializer': 'glorot_uniform'}} \n",
      "\n",
      "\n",
      "{'F1 whole': 0.7000394166338195, 'weights': array([[0.26288077, 0.26288077, 0.26288077, 1.2628766 ],\n",
      "       [0.46816546, 0.46816546, 1.4681605 , 0.46816546],\n",
      "       [0.5737834 , 1.573785  , 0.5737834 , 0.5737834 ],\n",
      "       [1.2703496 , 0.27036586, 0.27036586, 0.27036586]], dtype=float32), 'F1 removed noise': 0.7797924057285508, 'parameters': {'nodes': 128, 'activation': <class 'keras.layers.advanced_activations.LeakyReLU'>, 'deeper': False, 'initializer': 'he_normal'}} \n",
      "\n",
      "\n",
      "{'F1 whole': 0.7251346734988832, 'weights': array([[0.26825538, 0.26825538, 0.26825538, 1.2682513 ],\n",
      "       [0.47072563, 0.47072563, 1.4707242 , 0.47072563],\n",
      "       [0.52984345, 1.5298338 , 0.52984345, 0.52984345],\n",
      "       [1.2614881 , 0.26146793, 0.26146793, 0.26146793]], dtype=float32), 'F1 removed noise': 0.7837340691104979, 'parameters': {'nodes': 128, 'activation': <class 'keras.layers.advanced_activations.LeakyReLU'>, 'deeper': False, 'initializer': 'he_normal'}} \n",
      "\n",
      "\n",
      "{'F1 whole': 0.7401129943502824, 'weights': array([[0.2742534 , 0.2742534 , 0.2742534 , 1.2742516 ],\n",
      "       [0.47743914, 0.47743914, 1.4774336 , 0.47743914],\n",
      "       [0.53553337, 1.5355417 , 0.53553337, 0.53553337],\n",
      "       [1.2737676 , 0.27376068, 0.27376068, 0.27376068]], dtype=float32), 'F1 removed noise': 0.793062672447773, 'parameters': {'nodes': 128, 'activation': <class 'keras.layers.advanced_activations.LeakyReLU'>, 'deeper': False, 'initializer': 'glorot_uniform'}} \n",
      "\n",
      "\n",
      "{'F1 whole': 0.7313099461306004, 'weights': array([[0.26573056, 0.26573056, 0.26573056, 1.2657144 ],\n",
      "       [0.4745736 , 0.4745736 , 1.4745754 , 0.4745736 ],\n",
      "       [0.54523534, 1.5452223 , 0.54523534, 0.54523534],\n",
      "       [1.267515  , 0.26751056, 0.26751056, 0.26751056]], dtype=float32), 'F1 removed noise': 0.7905662856392063, 'parameters': {'nodes': 128, 'activation': <class 'keras.layers.advanced_activations.LeakyReLU'>, 'deeper': False, 'initializer': 'glorot_uniform'}} \n",
      "\n",
      "\n",
      "{'F1 whole': 0.7211930101169359, 'weights': array([[0.28924978, 0.28924978, 0.28924978, 1.2892362 ],\n",
      "       [0.4449879 , 0.4449879 , 1.4449766 , 0.4449879 ],\n",
      "       [0.5197859 , 1.5197852 , 0.5197859 , 0.5197859 ],\n",
      "       [1.2834281 , 0.28341946, 0.28341946, 0.28341946]], dtype=float32), 'F1 removed noise': 0.7851793456838786, 'parameters': {'nodes': 128, 'activation': <class 'keras.layers.advanced_activations.ELU'>, 'deeper': False, 'initializer': 'he_normal'}} \n",
      "\n",
      "\n",
      "{'F1 whole': 0.7052949678097491, 'weights': array([[0.27946633, 0.27946633, 0.27946633, 1.2794603 ],\n",
      "       [0.42959645, 0.42959645, 1.4295926 , 0.42959645],\n",
      "       [0.5364025 , 1.5363905 , 0.5364025 , 0.5364025 ],\n",
      "       [1.2648818 , 0.26487976, 0.26487976, 0.26487976]], dtype=float32), 'F1 removed noise': 0.7900407305216135, 'parameters': {'nodes': 128, 'activation': <class 'keras.layers.advanced_activations.ELU'>, 'deeper': False, 'initializer': 'he_normal'}} \n",
      "\n",
      "\n",
      "{'F1 whole': 0.7081855209565103, 'weights': array([[0.2865974 , 0.2865974 , 0.2865974 , 1.2865965 ],\n",
      "       [0.45299193, 0.45299193, 1.4529871 , 0.45299193],\n",
      "       [0.5413758 , 1.5413823 , 0.5413758 , 0.5413758 ],\n",
      "       [1.2840872 , 0.28408447, 0.28408447, 0.28408447]], dtype=float32), 'F1 removed noise': 0.7921429509919853, 'parameters': {'nodes': 128, 'activation': <class 'keras.layers.advanced_activations.ELU'>, 'deeper': False, 'initializer': 'glorot_uniform'}} \n",
      "\n",
      "\n",
      "{'F1 whole': 0.712915517014847, 'weights': array([[0.28077063, 0.28077063, 0.28077063, 1.2807792 ],\n",
      "       [0.45531338, 0.45531338, 1.4552982 , 0.45531338],\n",
      "       [0.5396012 , 1.5395921 , 0.5396012 , 0.5396012 ],\n",
      "       [1.2853366 , 0.2853428 , 0.2853428 , 0.2853428 ]], dtype=float32), 'F1 removed noise': 0.7809749047431348, 'parameters': {'nodes': 128, 'activation': <class 'keras.layers.advanced_activations.ELU'>, 'deeper': False, 'initializer': 'glorot_uniform'}} \n",
      "\n",
      "\n",
      "{'F1 whole': 0.712389961897254, 'weights': array([[0.284057  , 0.284057  , 0.284057  , 1.284049  ],\n",
      "       [0.47237873, 0.47237873, 1.472372  , 0.47237873],\n",
      "       [0.54327667, 1.5432578 , 0.54327667, 0.54327667],\n",
      "       [1.2722878 , 0.27229965, 0.27229965, 0.27229965]], dtype=float32), 'F1 removed noise': 0.7846537905662856, 'parameters': {'nodes': 164, 'activation': <class 'keras.layers.advanced_activations.LeakyReLU'>, 'deeper': True, 'initializer': 'he_normal'}} \n",
      "\n",
      "\n",
      "{'F1 whole': 0.7156746813822099, 'weights': array([[0.26581126, 0.26581126, 0.26581126, 1.265804  ],\n",
      "       [0.4615126 , 0.4615126 , 1.461522  , 0.4615126 ],\n",
      "       [0.5522839 , 1.5522926 , 0.5522839 , 0.5522839 ],\n",
      "       [1.2661488 , 0.2661649 , 0.2661649 , 0.2661649 ]], dtype=float32), 'F1 removed noise': 0.7918801734331887, 'parameters': {'nodes': 164, 'activation': <class 'keras.layers.advanced_activations.LeakyReLU'>, 'deeper': True, 'initializer': 'he_normal'}} \n",
      "\n",
      "\n",
      "{'F1 whole': 0.7493102089081592, 'weights': array([[0.28856373, 0.28856373, 0.28856373, 1.2885695 ],\n",
      "       [0.4676625 , 0.4676625 , 1.4676499 , 0.4676625 ],\n",
      "       [0.5372526 , 1.5372689 , 0.5372526 , 0.5372526 ],\n",
      "       [1.2662562 , 0.26626503, 0.26626503, 0.26626503]], dtype=float32), 'F1 removed noise': 0.7897779529628168, 'parameters': {'nodes': 164, 'activation': <class 'keras.layers.advanced_activations.LeakyReLU'>, 'deeper': True, 'initializer': 'glorot_uniform'}} \n",
      "\n",
      "\n",
      "{'F1 whole': 0.7481277098935751, 'weights': array([[0.2737267 , 0.2737267 , 0.2737267 , 1.2737273 ],\n",
      "       [0.4705268 , 0.4705268 , 1.4705387 , 0.4705268 ],\n",
      "       [0.51580334, 1.5158023 , 0.51580334, 0.51580334],\n",
      "       [1.2809952 , 0.28100118, 0.28100118, 0.28100118]], dtype=float32), 'F1 removed noise': 0.7857049008014716, 'parameters': {'nodes': 164, 'activation': <class 'keras.layers.advanced_activations.LeakyReLU'>, 'deeper': True, 'initializer': 'glorot_uniform'}} \n",
      "\n",
      "\n",
      "{'F1 whole': 0.6968860859282617, 'weights': array([[0.29388267, 0.29388267, 0.29388267, 1.293881  ],\n",
      "       [0.4534327 , 0.4534327 , 1.4534168 , 0.4534327 ],\n",
      "       [0.52195996, 1.5219792 , 0.52195996, 0.52195996],\n",
      "       [1.2876918 , 0.28771082, 0.28771082, 0.28771082]], dtype=float32), 'F1 removed noise': 0.7726974116410459, 'parameters': {'nodes': 164, 'activation': <class 'keras.layers.advanced_activations.ELU'>, 'deeper': True, 'initializer': 'he_normal'}} \n",
      "\n",
      "\n",
      "{'F1 whole': 0.7093680199710943, 'weights': array([[0.28088433, 0.28088433, 0.28088433, 1.2808872 ],\n",
      "       [0.44796354, 0.44796354, 1.4479451 , 0.44796354],\n",
      "       [0.5585116 , 1.5585055 , 0.5585116 , 0.5585116 ],\n",
      "       [1.2641221 , 0.2641223 , 0.2641223 , 0.2641223 ]], dtype=float32), 'F1 removed noise': 0.780449349625542, 'parameters': {'nodes': 164, 'activation': <class 'keras.layers.advanced_activations.ELU'>, 'deeper': True, 'initializer': 'he_normal'}} \n",
      "\n",
      "\n",
      "{'F1 whole': 0.6696886085928262, 'weights': array([[0.27879068, 0.27879068, 0.27879068, 1.278794  ],\n",
      "       [0.45209166, 0.45209166, 1.4520842 , 0.45209166],\n",
      "       [0.54583997, 1.5458363 , 0.54583997, 0.54583997],\n",
      "       [1.2844793 , 0.28449106, 0.28449106, 0.28449106]], dtype=float32), 'F1 removed noise': 0.7719090789646564, 'parameters': {'nodes': 164, 'activation': <class 'keras.layers.advanced_activations.ELU'>, 'deeper': True, 'initializer': 'glorot_uniform'}} \n",
      "\n",
      "\n",
      "{'F1 whole': 0.7441860465116278, 'weights': array([[0.29721618, 0.29721618, 0.29721618, 1.297212  ],\n",
      "       [0.4410298 , 0.4410298 , 1.4410416 , 0.4410298 ],\n",
      "       [0.53594226, 1.5359489 , 0.53594226, 0.53594226],\n",
      "       [1.276442  , 0.2764335 , 0.2764335 , 0.2764335 ]], dtype=float32), 'F1 removed noise': 0.784916568125082, 'parameters': {'nodes': 164, 'activation': <class 'keras.layers.advanced_activations.ELU'>, 'deeper': True, 'initializer': 'glorot_uniform'}} \n",
      "\n",
      "\n",
      "{'F1 whole': 0.7493102089081592, 'weights': array([[0.2741991 , 0.2741991 , 0.2741991 , 1.2742037 ],\n",
      "       [0.46814147, 0.46814147, 1.4681404 , 0.46814147],\n",
      "       [0.5433139 , 1.5433131 , 0.5433139 , 0.5433139 ],\n",
      "       [1.2711474 , 0.27113906, 0.27113906, 0.27113906]], dtype=float32), 'F1 removed noise': 0.7914860070949941, 'parameters': {'nodes': 164, 'activation': <class 'keras.layers.advanced_activations.LeakyReLU'>, 'deeper': False, 'initializer': 'he_normal'}} \n",
      "\n",
      "\n",
      "{'F1 whole': 0.7197477335435554, 'weights': array([[0.26353177, 0.26353177, 0.26353177, 1.2635161 ],\n",
      "       [0.47309417, 0.47309417, 1.4730859 , 0.47309417],\n",
      "       [0.5600366 , 1.5600342 , 0.5600366 , 0.5600366 ],\n",
      "       [1.2686104 , 0.26860708, 0.26860708, 0.26860708]], dtype=float32), 'F1 removed noise': 0.788726842727631, 'parameters': {'nodes': 164, 'activation': <class 'keras.layers.advanced_activations.LeakyReLU'>, 'deeper': False, 'initializer': 'he_normal'}} \n",
      "\n",
      "\n",
      "{'F1 whole': 0.6875574825909867, 'weights': array([[0.266056  , 0.266056  , 0.266056  , 1.2660702 ],\n",
      "       [0.46608022, 0.46608022, 1.4660769 , 0.46608022],\n",
      "       [0.5499333 , 1.5499336 , 0.5499333 , 0.5499333 ],\n",
      "       [1.2744979 , 0.2744864 , 0.2744864 , 0.2744864 ]], dtype=float32), 'F1 removed noise': 0.7846537905662856, 'parameters': {'nodes': 164, 'activation': <class 'keras.layers.advanced_activations.LeakyReLU'>, 'deeper': False, 'initializer': 'glorot_uniform'}} \n",
      "\n",
      "\n",
      "{'F1 whole': 0.7306530022336093, 'weights': array([[0.26997122, 0.26997122, 0.26997122, 1.2699609 ],\n",
      "       [0.46726915, 0.46726915, 1.4672729 , 0.46726915],\n",
      "       [0.5340617 , 1.5340562 , 0.5340617 , 0.5340617 ],\n",
      "       [1.2729688 , 0.27295393, 0.27295393, 0.27295393]], dtype=float32), 'F1 removed noise': 0.7867560110366575, 'parameters': {'nodes': 164, 'activation': <class 'keras.layers.advanced_activations.LeakyReLU'>, 'deeper': False, 'initializer': 'glorot_uniform'}} \n",
      "\n",
      "\n",
      "{'F1 whole': 0.7114702404414663, 'weights': array([[0.27381173, 0.27381173, 0.27381173, 1.2737957 ],\n",
      "       [0.4666281 , 0.4666281 , 1.4666321 , 0.4666281 ],\n",
      "       [0.53126395, 1.5312495 , 0.53126395, 0.53126395],\n",
      "       [1.2872816 , 0.28729063, 0.28729063, 0.28729063]], dtype=float32), 'F1 removed noise': 0.7850479569044804, 'parameters': {'nodes': 164, 'activation': <class 'keras.layers.advanced_activations.ELU'>, 'deeper': False, 'initializer': 'he_normal'}} \n",
      "\n",
      "\n",
      "{'F1 whole': 0.707528577059519, 'weights': array([[0.28475064, 0.28475064, 0.28475064, 1.2847583 ],\n",
      "       [0.44946536, 0.44946536, 1.4494601 , 0.44946536],\n",
      "       [0.52737176, 1.527387  , 0.52737176, 0.52737176],\n",
      "       [1.276819  , 0.27680597, 0.27680597, 0.27680597]], dtype=float32), 'F1 removed noise': 0.7879385100512416, 'parameters': {'nodes': 164, 'activation': <class 'keras.layers.advanced_activations.ELU'>, 'deeper': False, 'initializer': 'he_normal'}} \n",
      "\n",
      "\n",
      "{'F1 whole': 0.7116016292208645, 'weights': array([[0.27614167, 0.27614167, 0.27614167, 1.2761334 ],\n",
      "       [0.4474415 , 0.4474415 , 1.4474397 , 0.4474415 ],\n",
      "       [0.5256155 , 1.5256155 , 0.5256155 , 0.5256155 ],\n",
      "       [1.274266  , 0.27427316, 0.27427316, 0.27427316]], dtype=float32), 'F1 removed noise': 0.7917487846537906, 'parameters': {'nodes': 164, 'activation': <class 'keras.layers.advanced_activations.ELU'>, 'deeper': False, 'initializer': 'glorot_uniform'}} \n",
      "\n",
      "\n",
      "{'F1 whole': 0.7013533044278019, 'weights': array([[0.2856537, 0.2856537, 0.2856537, 1.2856638],\n",
      "       [0.4625445, 0.4625445, 1.4625452, 0.4625445],\n",
      "       [0.5277654, 1.5277529, 0.5277654, 0.5277654],\n",
      "       [1.2848632, 0.2848595, 0.2848595, 0.2848595]], dtype=float32), 'F1 removed noise': 0.776639075022993, 'parameters': {'nodes': 164, 'activation': <class 'keras.layers.advanced_activations.ELU'>, 'deeper': False, 'initializer': 'glorot_uniform'}} \n",
      "\n",
      "\n",
      "\n",
      "===== STATIC NOISE MODEL ======\n",
      "{'F1 whole': 0.7243463408224938, 'F1 removed noise': 0.7272368939692551, 'parameters': {'nodes': 64, 'activation': <class 'keras.layers.advanced_activations.LeakyReLU'>, 'deeper': True, 'initializer': 'he_normal'}} \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n===== DEFAULT BASE MODEL ======\")\n",
    "for i in results_def:\n",
    "    print(i, '\\n\\n')\n",
    "    \n",
    "print(\"\\n===== DYNAMIC NOISE MODEL ======\")\n",
    "for i in results_noise_dyn:\n",
    "    print(i, '\\n\\n')\n",
    "    \n",
    "print(\"\\n===== STATIC NOISE MODEL ======\")\n",
    "for i in results_noise_sta:\n",
    "    print(i, '\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score for default model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'dict' and 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-0511706bea96>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nAverage model score: %.3f%% (+/- %.3f%%)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_def\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_def\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\n\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitemgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitemgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpred_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nyuad/anaconda2/envs/Gabor/lib/python2.7/site-packages/numpy/core/fromnumeric.pyc\u001b[0m in \u001b[0;36mmean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m   2955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2956\u001b[0m     return _methods._mean(a, axis=axis, dtype=dtype,\n\u001b[0;32m-> 2957\u001b[0;31m                           out=out, **kwargs)\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/nyuad/anaconda2/envs/Gabor/lib/python2.7/site-packages/numpy/core/_methods.pyc\u001b[0m in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mis_float16_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         ret = um.true_divide(\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'dict' and 'dict'"
     ]
    }
   ],
   "source": [
    "print(\"\\nAverage model score: %.3f%% (+/- %.3f%%)\" % (np.mean(results_def), np.std(results_def)))\n",
    "print(results_def, '\\n\\n')\n",
    "pcm.plot_confusion_matrix(true_class=[max(enumerate(i), key=operator.itemgetter(1))[0] for i in y_test.tolist()], pred_class=[max(enumerate(i), key=operator.itemgetter(1))[0] for i in pred_def.tolist()], normalize=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score for Noise model and the final weight matrix it learnt. NORMALIZED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'F1 whole': 0.8344500279173646, 'weights': array([[0.23848289, 0.23848289, 1.2384899 ],\n",
      "       [0.5982076 , 1.5982155 , 0.5982076 ],\n",
      "       [1.3895782 , 0.38957942, 0.38957942]], dtype=float32), 'F1 removed noise': 0.8456169737576773, 'parameters': {'optimizer': <keras.optimizers.Adam object at 0x7f4eb8310750>, 'nodes': 128, 'activation': <keras.layers.advanced_activations.ELU object at 0x7f4eb8310610>, 'deeper': True, 'initializer': 'glorot_uniform'}}, {'F1 whole': 0.8375209380234506, 'weights': array([[0.24492241, 0.24492241, 1.2449113 ],\n",
      "       [0.6013491 , 1.601342  , 0.6013491 ],\n",
      "       [1.3814358 , 0.38143024, 0.38143024]], dtype=float32), 'F1 removed noise': 0.8489670575097711, 'parameters': {'optimizer': <keras.optimizers.Adam object at 0x7f4eb8310750>, 'nodes': 128, 'activation': <keras.layers.advanced_activations.ELU object at 0x7f4eb8310610>, 'deeper': True, 'initializer': 'glorot_uniform'}}] \n",
      "\n",
      "\n",
      "0    2.227707\n",
      "1    2.227695\n",
      "2    2.227691\n",
      "dtype: float32\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== CF Dyn whole system =====\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== CF Dyn base model =====\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(results_noise_dyn, '\\n\\n')\n",
    "print(np.sum(pd.DataFrame(dyn_model.layers[-3].get_weights()[0])))\n",
    "pcm.plot_confusion_matrix(calc=False, grid = dyn_model.layers[-3].get_weights()[0], normalize=True, title=\"Updated weight matrix\")\n",
    "print(\"==== CF Dyn whole system =====\")\n",
    "pcm.plot_confusion_matrix(true_class=[max(enumerate(i), key=operator.itemgetter(1))[0] for i in y_test.tolist()], pred_class=[max(enumerate(i), key=operator.itemgetter(1))[0] for i in pred_dyn.tolist()], normalize=True)\n",
    "print(\"==== CF Dyn base model =====\")\n",
    "pcm.plot_confusion_matrix(true_class=[max(enumerate(i), key=operator.itemgetter(1))[0] for i in y_test.tolist()], pred_class=[max(enumerate(i), key=operator.itemgetter(1))[0] for i in pred2_dyn.tolist()], normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score for model with static weight matrix and the confusion matrix it used as weight matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"\\nAverage Intermediary score: %.2f%% (+/- %.2f%%)\" % (np.mean(results_noise_sta), np.std(results_noise_sta)))\n",
    "print(\"\\nAverage model score: %.2f%% (+/- %.2f%%)\" % (np.mean(results_noise_sta_int), np.std(results_noise_sta_int)))\n",
    "print(results_noise_sta, '\\n\\n')\n",
    "pcm.plot_confusion_matrix(calc=False, grid = cm, normalize=True,  title=\"Static weight matrix\")\n",
    "print(np.sum(pd.DataFrame(cm)))\n",
    "print(\"==== CF Sta whole system =====\")\n",
    "pcm.plot_confusion_matrix(true_class=[max(enumerate(i), key=operator.itemgetter(1))[0] for i in y_test.tolist()], pred_class=[max(enumerate(i), key=operator.itemgetter(1))[0] for i in pred_sta.tolist()], normalize=True)\n",
    "print(\"==== CF Sta base model =====\")\n",
    "pcm.plot_confusion_matrix(true_class=[max(enumerate(i), key=operator.itemgetter(1))[0] for i in y_test.tolist()], pred_class=[max(enumerate(i), key=operator.itemgetter(1))[0] for i in pred2_sta.tolist()], normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
